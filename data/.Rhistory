column_differences <- abs(t[2:nrow(t), ] - t[1:(nrow(t) - 1), ])
# Count the number of non-zero differences for each column and sum all
non_zero_diff_count_empi <- sum(colSums(column_differences))
sum_runs <- c()
number_sim <- 10000
for (i in 1:number_sim){
shuffled_t <- matrix(nrow = nrow(t), ncol = ncol(t), 0)
for (j in 1:ncol(t)){
shuffled_t[ , j] <- t[sample(1:nrow(t), nrow(t), replace = FALSE), j]
}
column_differences <- abs(shuffled_t[2:nrow(shuffled_t), ] - shuffled_t[1:(nrow(shuffled_t) - 1), ])
non_zero_diff_count_shuffled <- sum(colSums(column_differences))
sum_runs <- c(sum_runs, non_zero_diff_count_shuffled)
}
bottom_2_5_percent <- unname(quantile(sum_runs, probs = 0.025))
density_data <- density(sum_runs)
density_df <- data.frame(x = density_data$x, y = density_data$y)
density_shaded <- subset(density_df, x <= bottom_2_5_percent)
density_shaded_above <- subset(density_df, x > bottom_2_5_percent)
g2 <- ggplot() +
geom_area(data = density_shaded, aes(x = x, y = y), fill = "#2f4b7c", alpha = 0.7) + # Shaded area
geom_area(data = density_shaded_above, aes(x = x, y = y), fill = "#fff4c2", alpha = 0.7) + # Shaded area
geom_line(data = density_df, aes(x = x, y = y), size = 1) + # Density curve
geom_vline(xintercept = non_zero_diff_count_empi,
linetype = "dashed",
color = "#cc0000", size = 1) + # Red vertical line + # Red vertical line
theme_bw() +
theme(panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank())+
labs(title = "Scientists",
x = "Runs",
y = "Density") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
g2
data <- read_dta('/Users/lsage/Documents/Sociologie/Recherche/Max Weber/Cumulative advantage/culture_change/output/psid.dta')
# Select relevant columns
data <- data %>% select(-women, -immigrant, -birthyearb, -birthyear, -cohort)
# Identify dependent variables
dependent_vars <- setdiff(names(data), c("age18", "pid", "svyyear", "age", "parent"))
#===================================================================================================
perform_runs_test <- function(data, variable, number_sim) {
small1 <- data %>%
select(pid, age, all_of(variable)) %>%
filter(!is.na(.data[[variable]]) & .data[[variable]] < 8)
small1 <- small1 %>%
group_by(pid) %>%
mutate(n_obs = n()) %>%
filter(n_obs > 2) %>%
mutate(value = get(variable)) %>%
ungroup()
number_sub_matrices <- length(unique(small1$n_obs))
values_sub_matrices <- unique(small1$n_obs)
sum_runs_tot <- matrix(nrow = number_sub_matrices, ncol = number_sim, 0)
empirical_runs <- c()
l <- 1
for (k in values_sub_matrices){
t1 <- small1 %>%
filter(n_obs == k) %>%
select(pid, value)
t1 <- matrix(t1$value, nrow = k, byrow = FALSE)
# each column is an individual, each row in a attitude value
# take the row minus the previous row to see whether there was a run:
column_differences <- abs(t1[2:nrow(t1), ] - t1[1:(nrow(t1) - 1), ])
empi <- sum(colSums(column_differences))
empirical_runs <- c(empirical_runs, empi)
sum_runs <- c()
for (i in 1:number_sim){
shuffled_t1 <- matrix(nrow = nrow(t1), ncol = ncol(t1), 0)
for (j in 1:ncol(t1)){
shuffled_t1[ , j] <- t1[sample(1:nrow(t1), nrow(t1), replace = FALSE), j]
}
column_differences <- abs(shuffled_t1[2:nrow(shuffled_t1), ] - shuffled_t1[1:(nrow(shuffled_t1) - 1), ])
non_zero_diff_count_shuffled <- sum(colSums(column_differences))
sum_runs <- c(sum_runs, non_zero_diff_count_shuffled)
}
sum_runs_tot[l,] <- sum_runs
l <- l + 1
}
sum_runs_tot <- colSums(sum_runs_tot)
empirical_runs <- sum(empirical_runs)
list(empirical = empirical_runs, simulated = sum_runs_tot)
}
#===================================================================================================
# Function to compute descriptive stats one variable
compute_descriptive_stats <- function(data, variable) {
small <- data %>%
select(pid, age, all_of(variable)) %>%
filter(!is.na(.data[[variable]]) & .data[[variable]] < 8)
big_n <- length(unique(small$pid))
small <- small %>%
group_by(pid) %>%
mutate(n_obs = n()) %>%
filter(n_obs > 2) %>%
mutate(med = median(get(variable)),
average = mean(get(variable)),
changed = ifelse(get(variable) != average, 1, 0)) %>% # checks whether the person changed his/her attitude
ungroup()
changers_data <- small %>%
group_by(pid) %>%
summarise(changed = min(changed))
tot_changers <- sum(changers_data$changed)
full_changers <- small %>%
group_by(pid) %>%
summarise(n = n(),
n_diff = length(unique(get(variable)))) %>%
filter(n == n_diff) %>%
nrow()
if (nrow(small) == 0) return(NULL)  # Skip if no data
# compute descriptive statistics:
t <- small %>%
summarise(N = n(),
mean = mean(get(variable)),
sd = sd(get(variable)),
min = min(get(variable)),
max = max(get(variable)),
ind = length(unique(pid)),
big_n = big_n,
var = variable,
tot_changers = tot_changers - full_changers)
return(t)
}
#===================================================================================================
# Loop through variables: for descriptive stats
stats_des <- c()
for (j in seq_along(dependent_vars)) {
variable <- dependent_vars[j]
result <- compute_descriptive_stats(data, variable)
print(result)
stats_des <- bind_rows(stats_des, result)
}
stats_des <- left_join(stats_des, store_stats, by = c("var" = "variable"))
#===================================================================================================
# Graph appendix, relationship between p-value and 'real' sample size:
g3 <- ggplot(stats_des, aes(x = tot_changers, y = p_value)) +
geom_point(size = 2,  alpha = 0.8, shape = 21, fill = "blue", stroke = 0.5) +
labs(
x = "Effective sample size",
y = "P-value"
) +
theme_bw() +
theme(
axis.text = element_text(size = 12),
panel.grid.major = element_line(size = 0.5),
panel.grid.minor = element_blank()
)
g3
data <- read_dta('/Users/lsage/Documents/Sociologie/Recherche/Max Weber/Cumulative advantage/culture_change/output/psid.dta')
# Select relevant columns
data <- data %>% select(-women, -immigrant, -birthyearb, -birthyear, -cohort)
# Identify dependent variables
dependent_vars <- setdiff(names(data), c("age18", "pid", "svyyear", "age", "parent"))
#===================================================================================================
perform_runs_test <- function(data, variable, number_sim) {
small1 <- data %>%
select(pid, age, all_of(variable)) %>%
filter(!is.na(.data[[variable]]) & .data[[variable]] < 8)
small1 <- small1 %>%
group_by(pid) %>%
mutate(n_obs = n()) %>%
filter(n_obs > 2) %>%
mutate(value = get(variable)) %>%
ungroup()
number_sub_matrices <- length(unique(small1$n_obs))
values_sub_matrices <- unique(small1$n_obs)
sum_runs_tot <- matrix(nrow = number_sub_matrices, ncol = number_sim, 0)
empirical_runs <- c()
l <- 1
for (k in values_sub_matrices){
t1 <- small1 %>%
filter(n_obs == k) %>%
select(pid, value)
t1 <- matrix(t1$value, nrow = k, byrow = FALSE)
# each column is an individual, each row in a attitude value
# take the row minus the previous row to see whether there was a run:
column_differences <- abs(t1[2:nrow(t1), ] - t1[1:(nrow(t1) - 1), ])
empi <- sum(colSums(column_differences))
empirical_runs <- c(empirical_runs, empi)
sum_runs <- c()
for (i in 1:number_sim){
shuffled_t1 <- matrix(nrow = nrow(t1), ncol = ncol(t1), 0)
for (j in 1:ncol(t1)){
shuffled_t1[ , j] <- t1[sample(1:nrow(t1), nrow(t1), replace = FALSE), j]
}
column_differences <- abs(shuffled_t1[2:nrow(shuffled_t1), ] - shuffled_t1[1:(nrow(shuffled_t1) - 1), ])
non_zero_diff_count_shuffled <- sum(colSums(column_differences))
sum_runs <- c(sum_runs, non_zero_diff_count_shuffled)
}
sum_runs_tot[l,] <- sum_runs
l <- l + 1
}
sum_runs_tot <- colSums(sum_runs_tot)
empirical_runs <- sum(empirical_runs)
list(empirical = empirical_runs, simulated = sum_runs_tot)
}
#===================================================================================================
# runs test without transforming variable into dichotomous variable
# Set simulation parameters
number_sim <- 100
empirical_stats <- numeric(length(dependent_vars))
distributions <- matrix(0, nrow = number_sim, ncol = length(dependent_vars))
variables <- character(0)
# Loop through variables
for (j in seq_along(dependent_vars)) {
variable <- dependent_vars[j]
result <- perform_runs_test(data, variable, number_sim)
if (!is.null(result)) {
empirical_stats[j] <- result$empirical
distributions[, j] <- result$simulated
variables <- c(variables, variable)
print(paste("Processed:", variable, Sys.time()))
}
}
# Save results
save(distributions, file = "distributions_optimized_non_transformed.saved")
save(empirical_stats, file = "empirical_stats_optimized_non_transformed.saved")
store_stats <- matrix(nrow = length(variables), ncol = 6) # one col for pvalues, other for different values of power
for (j in seq_along(variables)) {
# find the exact position of the empirical value in the distribution
#reverse the order, so that the lowest value is the first one
distributions[,j] <- sort(distributions[,j], decreasing = FALSE)
# now for each column tell me the row in which the empirical would be in the distribution
store_stats[j, 1] <- sum(distributions[,j] <= empirical_stats[j]) / number_sim
for (percent_change in c(1, 2, 3, 4, 5)){
# For each test compute the power for different values of the effect:
bottom_2_5_percent <- unname(quantile(unname(distributions[,j]), probs = 0.025))
distribution_h1_bottom <- distributions[,j] * (1 - (percent_change / 100))
distribution_h1_bottom <- sort(distribution_h1_bottom, decreasing = TRUE)
# now for each column tell where the empirical value would be in the distribution
store_stats[j, percent_change + 1] <- sum(distribution_h1_bottom <= bottom_2_5_percent) / length(distribution_h1_bottom)
}
}
store_stats <- as.data.frame(store_stats)
names(store_stats) <- c("p_value", "power_001", "power_002",
'power_003', "power_004", "power_005")
store_stats$variable <- variables
store_stats <- store_stats %>%
mutate(p_value = ifelse(p_value <= 0.5, p_value * 2, 2 * (1 - p_value)))
# Save p-values
save(store_stats, file = "p_values_optimized_with_power.saved")
write.csv(store_stats, "store_stats.csv")
#===================================================================================================
load("p_values_optimized_with_power.saved")
load("distributions_optimized_binary_with_power.saved")
load("empirical_stats_optimized_binary_with_power.saved")
distributions <- as.data.frame(t(distributions))
distributions$variable <- store_stats$variable
distributions <- distributions[!grepl("cds", distributions$variable), ]
distributions <- distributions %>%
select(-variable)
distributions <- t(as.matrix(distributions))
sim_distribution <- rowSums(distributions)
# get rid of 0s in empirical_stats
empirical_stats <- empirical_stats[empirical_stats != 0]
empirical_distribution <- data.frame(empirical_stats, variable = store_stats$variable)
empirical_distribution <- empirical_distribution[!grepl("cds", empirical_distribution$variable), ]
sum_empirical <- sum(empirical_distribution$empirical_stats)
bottom_2_5_percent <- unname(quantile(sim_distribution, probs = 0.025))
density_data <- density(sim_distribution)
density_df <- data.frame(x = density_data$x, y = density_data$y)
density_shaded <- subset(density_df, x <= bottom_2_5_percent)
density_shaded_above <- subset(density_df, x > bottom_2_5_percent)
g4 <- ggplot() +
geom_area(data = density_shaded, aes(x = x, y = y), fill = "#2f4b7c", alpha = 0.7) +
geom_area(data = density_shaded_above, aes(x = x, y = y), fill = "#fff4c2", alpha = 0.7) +
geom_line(data = density_df, aes(x = x, y = y), size = 1) +
geom_vline(xintercept = sum_empirical,
linetype = "dashed",
color = "#cc0000", size = 1) +
theme_bw() +
theme(panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank())+
labs(title = "Attitudes",
x = "Runs",
y = "Density") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
g4
#===================================================================================================
# Function to compute descriptive stats one variable
compute_descriptive_stats <- function(data, variable) {
small <- data %>%
select(pid, age, all_of(variable)) %>%
filter(!is.na(.data[[variable]]) & .data[[variable]] < 8)
big_n <- length(unique(small$pid))
small <- small %>%
group_by(pid) %>%
mutate(n_obs = n()) %>%
filter(n_obs > 2) %>%
mutate(med = median(get(variable)),
average = mean(get(variable)),
changed = ifelse(get(variable) != average, 1, 0)) %>% # checks whether the person changed his/her attitude
ungroup()
changers_data <- small %>%
group_by(pid) %>%
summarise(changed = min(changed))
tot_changers <- sum(changers_data$changed)
full_changers <- small %>%
group_by(pid) %>%
summarise(n = n(),
n_diff = length(unique(get(variable)))) %>%
filter(n == n_diff) %>%
nrow()
if (nrow(small) == 0) return(NULL)  # Skip if no data
# compute descriptive statistics:
t <- small %>%
summarise(N = n(),
mean = mean(get(variable)),
sd = sd(get(variable)),
min = min(get(variable)),
max = max(get(variable)),
ind = length(unique(pid)),
big_n = big_n,
var = variable,
tot_changers = tot_changers - full_changers)
return(t)
}
()
#===================================================================================================
# Loop through variables: for descriptive stats
stats_des <- c()
for (j in seq_along(dependent_vars)) {
variable <- dependent_vars[j]
result <- compute_descriptive_stats(data, variable)
stats_des <- bind_rows(stats_des, result)
}
load("p_values_optimized_with_power.saved")
stats_des <- left_join(stats_des, store_stats, by = c("var" = "variable"))
stats_des <- stats_des %>%
select(var, big_n, ind, tot_changers, N, mean, sd, min, max, p_value)
# Create a latex table
latex_table <- kable(stats_des, format = "latex", booktabs = TRUE)
# Save
writeLines(latex_table, "table.tex")
#===================================================================================================
# Graph appendix, relationship between p-value and 'real' sample size:
g4 <- ggplot(stats_des, aes(x = tot_changers, y = p_value)) +
geom_point(size = 2,  alpha = 0.8, shape = 21, fill = "blue", stroke = 0.5) +
labs(
x = "Effective sample size",
y = "P-value"
) +
theme_bw() +
theme(
axis.text = element_text(size = 12),
panel.grid.major = element_line(size = 0.5),
panel.grid.minor = element_blank()
)
g4
ggsave("figureS1.pdf",
plot=g4, device = "jpeg",
width = 8.5, height = 8.5,
units = "cm",
dpi = 1200,
useDingbats = FALSE)
ggsave("figureS1.pdf",
plot=g4, device = "jpeg",
width = 8.5, height = 8.5,
units = "cm",
dpi = 1200,
useDingbats = FALSE)
ggsave("figureS1.pdf",
plot=g4, device = "jpeg",
width = 8.5, height = 8.5,
units = "cm",
dpi = 1200)
ggsave("figureS1.pdf",
plot=g4, device = "jpeg",
width = 8.5, height = 8.5,
units = "cm",
dpi = 1200)
ggsave("figureS1.pdf",
plot=g4, device = "pdf",
width = 8.5, height = 8.5,
units = "cm",
dpi = 1200,
useDingbats = FALSE))
ggsave("figureS1.pdf",
plot=g4, device = "pdf",
width = 8.5, height = 8.5,
units = "cm",
dpi = 1200,
useDingbats = FALSE)
# Check if dplyr packages are installed and if not install and load them
if (!requireNamespace("dplyr", quietly = TRUE)) {
install.packages("dplyr")
}
library(dplyr)
if (!requireNamespace("ggplot2", quietly = TRUE)) {
install.packages("ggplot2")
}
library(ggplot2)
if (!requireNamespace("haven", quietly = TRUE)) {
install.packages("haven")
}
library(haven)
#------------------------------------------------------------------------------------------
# Same graphs with only scientists who have 50 publications or more
small<-read_dta(paste0(your_path,"/scientists.dta"))
your_path<-""
#------------------------------------------------------------------------------------------
# Same graphs with only scientists who have 50 publications or more
small<-read_dta(paste0(your_path,"/scientists.dta"))
#------------------------------------------------------------------------------------------
# Same graphs with only scientists who have 50 publications or more
small<-read_dta("scientists.dta")
small<-small%>%
group_by(authorId)%>%
mutate(t=1,
paperNumber=cumsum(t),
N=n())
small<-small%>%
filter(N>49)
# Number of scientists:
length(unique(small$authorId))
# Number papers in sequential order:
small<-small%>%
group_by(authorId)%>%
mutate(t=1,
k=cumsum(t))
# log transform (add + 1 for papers with no citations in 10 years)
small<-small%>%
mutate(logCit=log(cit10+1))
# compute q per researcher:
small<-small%>%
group_by(authorId)%>%
mutate(q=mean(logCit))
# compute p: deviation from author q
small$p<-small$q-small$logCit
# find c parameter
c<-var(small$p)/var(small$q)
# compute the elements needed to follow equation in appendix
small<-small%>%
group_by(authorId)%>%
mutate(cumsumPrev=cumsum(logCit), # cumulative citation per author
x_1=lag(cumsumPrev),       # same in t-1
k_1=lag(k),                # paper number in t-1
denominator=k_1+c,
division=x_1/denominator,
tot=logCit-division)
# compute the variance per k
res<-small%>%
group_by(k)%>%
summarise(v=var(tot,na.rm=TRUE))
main_plot<-ggplot(res,aes(x=k,y=v))+
geom_point(color="Orchid",alpha=0.8)+
geom_smooth(color="red",se=FALSE)+
labs(
x = "n",
# y = expression(bold(paste("Variance(", Z[n],")")))
y = expression(paste("Variance(", Z[n],")"))
) +
scale_y_continuous(limits=c(0.95,1.25), expand = c(0, 0))+
scale_x_continuous(limits=c(0,50), expand = c(0, 0))+
theme_bw() +
theme(
# axis.title = element_text(size = 14,face = "bold"),
# panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
# panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank()
)
main_plot
ggsave("images/figureS2.pdf",
plot=main_plot, device = "pdf",
width = 10, height = 8,
units = "cm",
dpi = 1200,
useDingbats = FALSE)
#------------------------------------------------------------------------------------------
tot<-c()
for (i in 1:20){
small<-small%>%
group_by(authorId)%>%
mutate(x_k_t=cumsum(logCit),
lag_x_k_t=lag(x_k_t),
full=logCit-(lag_x_k_t/(paperNumber+i)))
small2<-small%>%
group_by(paperNumber)%>%
summarise(v=var(full))%>%
filter(paperNumber<=50)
small2$c<-i
tot<-bind_rows(tot,small2)
print(i)
}
tot$c_bis<-as.factor(paste0("c=", tot$c))
tot$c_bis <- factor(tot$c_bis, levels = c("c=1", "c=2", "c=3", "c=4", "c=5", "c=6", "c=7", "c=8",
"c=9", "c=10", "c=11", "c=12", "c=13", "c=14", "c=15",
"c=16", "c=17", "c=18", "c=19", "c=20"))
g<-ggplot(tot,aes(x=paperNumber,y=v)) +
facet_wrap(~c_bis) +
geom_point(color="Orchid",alpha=0.8)+
geom_smooth(se=FALSE,color="red")+  scale_y_continuous(limits=c(1,1.25))+
labs(
x = "n",
y = expression(paste("Variance(", Z[n],")"))
)  +
theme_bw() +
theme(
axis.title = element_text(size = 14),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank(),
strip.text = element_text(color = "black",face="bold"),
strip.background = element_rect(fill = "seashell2")
)
g
ggsave("images/figureS3.pdf",
plot=g, device = "pdf",
width = 20, height = 15,
units = "cm",
dpi = 1200,
useDingbats = FALSE)
